{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a302f4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in e:\\anaconda\\lib\\site-packages (2.14.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.14.0 in e:\\anaconda\\lib\\site-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in e:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in e:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in e:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in e:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in e:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in e:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in e:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in e:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in e:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in e:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in e:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in e:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.24.3)\n",
      "Requirement already satisfied: setuptools in e:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in e:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in e:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in e:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in e:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in e:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in e:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.59.0)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in e:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in e:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in e:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in e:\\anaconda\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.14.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in e:\\anaconda\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.23.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in e:\\anaconda\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in e:\\anaconda\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in e:\\anaconda\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in e:\\anaconda\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in e:\\anaconda\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in e:\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in e:\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in e:\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in e:\\anaconda\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in e:\\anaconda\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in e:\\anaconda\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in e:\\anaconda\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: keras in e:\\anaconda\\lib\\site-packages (2.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6301e5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09cd1afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Logistic Regression: 85.68%\n",
      "[[6546  406]\n",
      " [1602 5467]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.87      6952\n",
      "           1       0.93      0.77      0.84      7069\n",
      "\n",
      "    accuracy                           0.86     14021\n",
      "   macro avg       0.87      0.86      0.86     14021\n",
      "weighted avg       0.87      0.86      0.86     14021\n",
      "\n",
      "85.67862491976321\n"
     ]
    }
   ],
   "source": [
    "# LOGISTIC REGRESSION\n",
    "data = pd.read_csv('credit card.csv')\n",
    "corr_matrix = data.corr()\n",
    "# Find and remove highly correlated features\n",
    "highly_correlated = set()  # Set to store the names of correlated columns\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.75:\n",
    "            colname = corr_matrix.columns[i]\n",
    "            highly_correlated.add(colname)\n",
    "data = data.drop(columns=highly_correlated.difference(['default payment next month']))\n",
    "data = data.drop(columns=('BILL_AMT1'))\n",
    "{'EDUCATION': 'EDU'}.items()\n",
    "def onehot_encode(df, column_dict):\n",
    "    df = df.copy()\n",
    "    for column, prefix in column_dict.items():\n",
    "        dummies = pd.get_dummies(df[column], prefix=prefix)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "        df = df.drop(column, axis=1)\n",
    "    return df\n",
    "def preprocess_inputs(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Drop ID\n",
    "    df = df.drop('ID', axis=1)\n",
    "    \n",
    "    df = onehot_encode(\n",
    "        df,\n",
    "        {\n",
    "            'EDUCATION': 'EDU',\n",
    "            'MARRIAGE': 'MAR',\n",
    "            'SEX': 'SEX'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Split df into X and y\n",
    "    y = df['default payment next month'].copy()\n",
    "    X = df.drop('default payment next month', axis=1).copy()\n",
    "    \n",
    "    from sklearn.datasets import make_classification\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    from imblearn.over_sampling import KMeansSMOTE\n",
    "    oversample = KMeansSMOTE(cluster_balance_threshold=0.00001)\n",
    "    X, y = oversample.fit_resample(X, y)\n",
    "    \n",
    "    # Scale X with a standard scaler\n",
    "    scaler = StandardScaler()\n",
    "    X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "    \n",
    "    return X, y\n",
    "X, y = preprocess_inputs(data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=123)\n",
    "\n",
    "models = {\n",
    "    LogisticRegression(): \"   Logistic Regression\",\n",
    "}\n",
    "\n",
    "for model in models.keys():\n",
    "    model.fit(X_train, y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "for model, name in models.items():\n",
    "    print(name + \": {:.2f}%\".format(model.score(X_test, y_test) * 100))\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred) * 100)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d7b32ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "[[5270 1682]\n",
      " [1005 6064]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.76      0.80      6952\n",
      "           1       0.78      0.86      0.82      7069\n",
      "\n",
      "    accuracy                           0.81     14021\n",
      "   macro avg       0.81      0.81      0.81     14021\n",
      "weighted avg       0.81      0.81      0.81     14021\n",
      "\n",
      "80.83588902360745\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "data = pd.read_csv('credit card.csv')\n",
    "corr_matrix = data.corr()\n",
    "# Find and remove highly correlated features\n",
    "highly_correlated = set()  # Set to store the names of correlated columns\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.75:\n",
    "            colname = corr_matrix.columns[i]\n",
    "            highly_correlated.add(colname)\n",
    "data = data.drop(columns=highly_correlated.difference(['default payment next month']))\n",
    "data = data.drop(columns=('BILL_AMT1'))\n",
    "{'EDUCATION': 'EDU'}.items()\n",
    "def onehot_encode(df, column_dict):\n",
    "    df = df.copy()\n",
    "    for column, prefix in column_dict.items():\n",
    "        dummies = pd.get_dummies(df[column], prefix=prefix)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "        df = df.drop(column, axis=1)\n",
    "    return df\n",
    "def preprocess_inputs(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Drop ID\n",
    "    df = df.drop('ID', axis=1)\n",
    "    \n",
    "    df = onehot_encode(\n",
    "        df,\n",
    "        {\n",
    "            'EDUCATION': 'EDU',\n",
    "            'MARRIAGE': 'MAR',\n",
    "            'SEX': 'SEX'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Split df into X and y\n",
    "    y = df['default payment next month'].copy()\n",
    "    X = df.drop('default payment next month', axis=1).copy()\n",
    "    \n",
    "    from sklearn.datasets import make_classification\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    from imblearn.over_sampling import KMeansSMOTE\n",
    "    oversample = KMeansSMOTE(cluster_balance_threshold=0.00001)\n",
    "    X, y = oversample.fit_resample(X, y)\n",
    "    \n",
    "    # Scale X with a standard scaler\n",
    "    scaler = StandardScaler()\n",
    "    X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "    \n",
    "    return X, y\n",
    "X, y = preprocess_inputs(data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=123)\n",
    "\n",
    "from sklearn import neighbors\n",
    "\n",
    "k=4000\n",
    "model1_knn=neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "model1_knn.fit(X_train,y_train)\n",
    "\n",
    "y_pred=model1_knn.predict(X_test)\n",
    "\n",
    "# Đánh giá kết quả\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "print('KNN')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9686bdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "[[6413  539]\n",
      " [1471 5598]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86      6952\n",
      "           1       0.91      0.79      0.85      7069\n",
      "\n",
      "    accuracy                           0.86     14021\n",
      "   macro avg       0.86      0.86      0.86     14021\n",
      "weighted avg       0.86      0.86      0.86     14021\n",
      "\n",
      "85.66436060195421\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "data = pd.read_csv('credit card.csv')\n",
    "corr_matrix = data.corr()\n",
    "# Find and remove highly correlated features\n",
    "highly_correlated = set()  # Set to store the names of correlated columns\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.75:\n",
    "            colname = corr_matrix.columns[i]\n",
    "            highly_correlated.add(colname)\n",
    "data = data.drop(columns=highly_correlated.difference(['default payment next month']))\n",
    "data = data.drop(columns=('BILL_AMT1'))\n",
    "{'EDUCATION': 'EDU'}.items()\n",
    "def onehot_encode(df, column_dict):\n",
    "    df = df.copy()\n",
    "    for column, prefix in column_dict.items():\n",
    "        dummies = pd.get_dummies(df[column], prefix=prefix)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "        df = df.drop(column, axis=1)\n",
    "    return df\n",
    "def preprocess_inputs(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Drop ID\n",
    "    df = df.drop('ID', axis=1)\n",
    "    \n",
    "    df = onehot_encode(\n",
    "        df,\n",
    "        {\n",
    "            'EDUCATION': 'EDU',\n",
    "            'MARRIAGE': 'MAR',\n",
    "            'SEX': 'SEX'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Split df into X and y\n",
    "    y = df['default payment next month'].copy()\n",
    "    X = df.drop('default payment next month', axis=1).copy()\n",
    "    \n",
    "    from sklearn.datasets import make_classification\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    from imblearn.over_sampling import KMeansSMOTE\n",
    "    oversample = KMeansSMOTE(cluster_balance_threshold=0.00001)\n",
    "    X, y = oversample.fit_resample(X, y)\n",
    "    \n",
    "    # Scale X with a standard scaler\n",
    "    scaler = StandardScaler()\n",
    "    X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "    \n",
    "    return X, y\n",
    "X, y = preprocess_inputs(data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=123)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Xây dựng mô hình SVM và huấn luyện trên tập huấn luyện\n",
    "model = SVC(kernel='poly', C=0.1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Thực hiện Cross Validation với 5 folds\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "\n",
    "# Dự đoán trên tập kiểm tra\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Đánh giá kết quả\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "print('SVM')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4617734b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classifier\n",
      "Accuracy score: 0.86\n",
      "Precision score: 0.92\n",
      "Recall score: 0.79\n",
      "F1 score: 0.85\n"
     ]
    }
   ],
   "source": [
    "# NEURAL NETWORK\n",
    "data = pd.read_csv('credit card.csv')\n",
    "corr_matrix = data.corr()\n",
    "# Find and remove highly correlated features\n",
    "highly_correlated = set()  # Set to store the names of correlated columns\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.75:\n",
    "            colname = corr_matrix.columns[i]\n",
    "            highly_correlated.add(colname)\n",
    "data = data.drop(columns=highly_correlated.difference(['default payment next month']))\n",
    "data = data.drop(columns=('BILL_AMT1'))\n",
    "{'EDUCATION': 'EDU'}.items()\n",
    "def onehot_encode(df, column_dict):\n",
    "    df = df.copy()\n",
    "    for column, prefix in column_dict.items():\n",
    "        dummies = pd.get_dummies(df[column], prefix=prefix)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "        df = df.drop(column, axis=1)\n",
    "    return df\n",
    "def preprocess_inputs(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Drop ID\n",
    "    df = df.drop('ID', axis=1)\n",
    "    \n",
    "    df = onehot_encode(\n",
    "        df,\n",
    "        {\n",
    "            'EDUCATION': 'EDU',\n",
    "            'MARRIAGE': 'MAR',\n",
    "            'SEX': 'SEX'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Split df into X and y\n",
    "    y = df['default payment next month'].copy()\n",
    "    X = df.drop('default payment next month', axis=1).copy()\n",
    "    \n",
    "    from sklearn.datasets import make_classification\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    from imblearn.over_sampling import KMeansSMOTE\n",
    "    oversample = KMeansSMOTE(cluster_balance_threshold=0.00001)\n",
    "    X, y = oversample.fit_resample(X, y)\n",
    "    \n",
    "    # Scale X with a standard scaler\n",
    "    scaler = StandardScaler()\n",
    "    X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "    \n",
    "    return X, y\n",
    "X, y = preprocess_inputs(data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=123)\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "mlp_classifier_model = MLPClassifier()\n",
    "mlp_classifier_model.fit(X_train, y_train)\n",
    "\n",
    "# Thực hiện Cross Validation với 5 folds\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "\n",
    "prediction = mlp_classifier_model.predict(X_test)\n",
    "\n",
    "# Calculate and print classification metrics\n",
    "print(\"MLP Classifier\")\n",
    "print(\"Accuracy score: {:.2f}\".format(accuracy_score(y_test, prediction)))\n",
    "print(\"Precision score: {:.2f}\".format(precision_score(y_test, prediction)))\n",
    "print(\"Recall score: {:.2f}\".format(recall_score(y_test, prediction)))\n",
    "print(\"F1 score: {:.2f}\".format(f1_score(y_test, prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f7b10ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree RMSE: 0.42746451447260514\n",
      "Random Forest RMSE: 0.34625365151092863\n",
      "Decision Tree Accuracy: 0.8172740888666999\n",
      "Random Forest Accuracy: 0.8801084088153484\n",
      "R2 Score: 0.5204002393959526\n",
      "Randomforest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88      6952\n",
      "           1       0.91      0.84      0.88      7069\n",
      "\n",
      "    accuracy                           0.88     14021\n",
      "   macro avg       0.88      0.88      0.88     14021\n",
      "weighted avg       0.88      0.88      0.88     14021\n",
      "\n",
      "Decision Tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      6952\n",
      "           1       0.81      0.83      0.82      7069\n",
      "\n",
      "    accuracy                           0.82     14021\n",
      "   macro avg       0.82      0.82      0.82     14021\n",
      "weighted avg       0.82      0.82      0.82     14021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('credit card.csv')\n",
    "corr_matrix = data.corr()\n",
    "# Find and remove highly correlated features\n",
    "highly_correlated = set()  # Set to store the names of correlated columns\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.75:\n",
    "            colname = corr_matrix.columns[i]\n",
    "            highly_correlated.add(colname)\n",
    "data = data.drop(columns=highly_correlated.difference(['default payment next month']))\n",
    "data = data.drop(columns=('BILL_AMT1'))\n",
    "{'EDUCATION': 'EDU'}.items()\n",
    "def onehot_encode(df, column_dict):\n",
    "    df = df.copy()\n",
    "    for column, prefix in column_dict.items():\n",
    "        dummies = pd.get_dummies(df[column], prefix=prefix)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "        df = df.drop(column, axis=1)\n",
    "    return df\n",
    "def preprocess_inputs(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Drop ID\n",
    "    df = df.drop('ID', axis=1)\n",
    "    \n",
    "    df = onehot_encode(\n",
    "        df,\n",
    "        {\n",
    "            'EDUCATION': 'EDU',\n",
    "            'MARRIAGE': 'MAR',\n",
    "            'SEX': 'SEX'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Split df into X and y\n",
    "    y = df['default payment next month'].copy()\n",
    "    X = df.drop('default payment next month', axis=1).copy()\n",
    "    \n",
    "    from sklearn.datasets import make_classification\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    from imblearn.over_sampling import KMeansSMOTE\n",
    "    oversample = KMeansSMOTE(cluster_balance_threshold=0.00001)\n",
    "    X, y = oversample.fit_resample(X, y)\n",
    "    \n",
    "    # Scale X with a standard scaler\n",
    "    scaler = StandardScaler()\n",
    "    X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "    \n",
    "    return X, y\n",
    "X, y = preprocess_inputs(data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=123)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_squared_error\n",
    "# Tạo mô hình Decision Tree và huấn luyện\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán trên tập kiểm tra và tính accuracy\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "\n",
    "# Tạo mô hình Random Forest và huấn luyện\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán trên tập kiểm tra và tính accuracy\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "\n",
    "# Tính r2_score\n",
    "r2 = r2_score(y_test, rf_predictions)\n",
    "\n",
    "# Tính RMSE\n",
    "dt_rmse = mean_squared_error(y_test, dt_predictions, squared=False)\n",
    "rf_rmse = mean_squared_error(y_test, rf_predictions, squared=False)\n",
    "\n",
    "# In ra kết quả\n",
    "print(\"Decision Tree RMSE:\", dt_rmse)\n",
    "print(\"Random Forest RMSE:\", rf_rmse)\n",
    "\n",
    "\n",
    "# In ra kết quả\n",
    "print(\"Decision Tree Accuracy:\", dt_accuracy)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "print(\"R2 Score:\", r2)\n",
    "print('Randomforest')\n",
    "print(classification_report(y_test, rf_predictions))\n",
    "print('Decision Tree')\n",
    "print(classification_report(y_test, dt_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb8d119f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1023/1023 [==============================] - 3s 2ms/step - loss: 0.5624 - accuracy: 0.8290\n",
      "Epoch 2/20\n",
      "1023/1023 [==============================] - 2s 2ms/step - loss: 0.3604 - accuracy: 0.8530\n",
      "Epoch 3/20\n",
      "1023/1023 [==============================] - 2s 2ms/step - loss: 0.3528 - accuracy: 0.8521\n",
      "Epoch 4/20\n",
      "1023/1023 [==============================] - 2s 2ms/step - loss: 0.3514 - accuracy: 0.8510\n",
      "Epoch 5/20\n",
      "1023/1023 [==============================] - 2s 2ms/step - loss: 0.3511 - accuracy: 0.8508\n",
      "Epoch 6/20\n",
      "1023/1023 [==============================] - 2s 2ms/step - loss: 0.3492 - accuracy: 0.8523\n",
      "Epoch 7/20\n",
      "1023/1023 [==============================] - 2s 2ms/step - loss: 0.3498 - accuracy: 0.8513\n",
      "Epoch 8/20\n",
      "1023/1023 [==============================] - 2s 2ms/step - loss: 0.3497 - accuracy: 0.8514\n",
      "Epoch 9/20\n",
      "1023/1023 [==============================] - 2s 2ms/step - loss: 0.3496 - accuracy: 0.8521\n",
      "Epoch 10/20\n",
      "1023/1023 [==============================] - 2s 2ms/step - loss: 0.3490 - accuracy: 0.8520\n",
      "Epoch 11/20\n",
      "1023/1023 [==============================] - 2s 2ms/step - loss: 0.3494 - accuracy: 0.8523\n",
      "Epoch 12/20\n",
      "1023/1023 [==============================] - 2s 2ms/step - loss: 0.3494 - accuracy: 0.8509\n",
      "Epoch 13/20\n",
      "1023/1023 [==============================] - 2s 2ms/step - loss: 0.3489 - accuracy: 0.8519\n",
      "Epoch 14/20\n",
      "1023/1023 [==============================] - 2s 2ms/step - loss: 0.3496 - accuracy: 0.8512\n",
      "Epoch 15/20\n",
      "1023/1023 [==============================] - 2s 2ms/step - loss: 0.3481 - accuracy: 0.8522\n",
      "Epoch 16/20\n",
      "1023/1023 [==============================] - 3s 3ms/step - loss: 0.3491 - accuracy: 0.8512\n",
      "Epoch 17/20\n",
      "1023/1023 [==============================] - 3s 3ms/step - loss: 0.3486 - accuracy: 0.8520\n",
      "Epoch 18/20\n",
      "1023/1023 [==============================] - 3s 3ms/step - loss: 0.3491 - accuracy: 0.8516\n",
      "Epoch 19/20\n",
      "1023/1023 [==============================] - 2s 2ms/step - loss: 0.3486 - accuracy: 0.8517\n",
      "Epoch 20/20\n",
      "1023/1023 [==============================] - 2s 2ms/step - loss: 0.3488 - accuracy: 0.8524\n",
      "['loss', 'accuracy']\n",
      "439/439 [==============================] - 1s 2ms/step - loss: 0.3472 - accuracy: 0.8526\n",
      "439/439 [==============================] - 1s 2ms/step\n",
      "Neural Network keras\n",
      "[[6457  495]\n",
      " [1571 5498]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.93      0.86      6952\n",
      "           1       0.92      0.78      0.84      7069\n",
      "\n",
      "    accuracy                           0.85     14021\n",
      "   macro avg       0.86      0.85      0.85     14021\n",
      "weighted avg       0.86      0.85      0.85     14021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "data = pd.read_csv('credit card.csv')\n",
    "corr_matrix = data.corr()\n",
    "# Find and remove highly correlated features\n",
    "highly_correlated = set()  # Set to store the names of correlated columns\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.75:\n",
    "            colname = corr_matrix.columns[i]\n",
    "            highly_correlated.add(colname)\n",
    "data = data.drop(columns=highly_correlated.difference(['default payment next month']))\n",
    "data = data.drop(columns=('BILL_AMT1'))\n",
    "{'EDUCATION': 'EDU'}.items()\n",
    "def onehot_encode(df, column_dict):\n",
    "    df = df.copy()\n",
    "    for column, prefix in column_dict.items():\n",
    "        dummies = pd.get_dummies(df[column], prefix=prefix)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "        df = df.drop(column, axis=1)\n",
    "    return df\n",
    "def preprocess_inputs(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Drop ID\n",
    "    df = df.drop('ID', axis=1)\n",
    "    \n",
    "    df = onehot_encode(\n",
    "        df,\n",
    "        {\n",
    "            'EDUCATION': 'EDU',\n",
    "            'MARRIAGE': 'MAR',\n",
    "            'SEX': 'SEX'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Split df into X and y\n",
    "    y = df['default payment next month'].copy()\n",
    "    X = df.drop('default payment next month', axis=1).copy()\n",
    "    \n",
    "    from sklearn.datasets import make_classification\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    from imblearn.over_sampling import KMeansSMOTE\n",
    "    oversample = KMeansSMOTE(cluster_balance_threshold=0.00001)\n",
    "    X, y = oversample.fit_resample(X, y)\n",
    "    \n",
    "    # Scale X with a standard scaler\n",
    "    scaler = StandardScaler()\n",
    "    X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "    \n",
    "    return X, y\n",
    "X, y = preprocess_inputs(data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=123)\n",
    "\n",
    "model = keras.Sequential([keras.layers.Dense(10,activation='sigmoid')])\n",
    "\n",
    "# model = keras.Sequential(\\                    # prepares to create a sequential neural network\n",
    "#  [keras.layers.Dense(10, \\                    # makes a complete network; size of output layer\n",
    "#                      activation='sigmoid')]\\  # activation function\n",
    "#                          )\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=opt,\\\n",
    "              loss='sparse_categorical_crossentropy',\\\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# fitting the model, like before\n",
    "model.fit(X_train, y_train, epochs=20)\n",
    "# Đánh giá kết quả\n",
    "print(model.metrics_names)\n",
    "model.evaluate(X_test, y_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "y_pred = model.predict(X_test)\n",
    "y_predclass = np.argmax(y_pred,axis=1) #\n",
    "\n",
    "cm = confusion_matrix(y_test, y_predclass)\n",
    "print('Neural Network keras')\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_predclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d742afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>29996</td>\n",
       "      <td>220000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>88004</td>\n",
       "      <td>31237</td>\n",
       "      <td>15980</td>\n",
       "      <td>8500</td>\n",
       "      <td>20000</td>\n",
       "      <td>5003</td>\n",
       "      <td>3047</td>\n",
       "      <td>5000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>29997</td>\n",
       "      <td>150000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>8979</td>\n",
       "      <td>5190</td>\n",
       "      <td>0</td>\n",
       "      <td>1837</td>\n",
       "      <td>3526</td>\n",
       "      <td>8998</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>29998</td>\n",
       "      <td>30000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>20878</td>\n",
       "      <td>20582</td>\n",
       "      <td>19357</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22000</td>\n",
       "      <td>4200</td>\n",
       "      <td>2000</td>\n",
       "      <td>3100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>29999</td>\n",
       "      <td>80000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>52774</td>\n",
       "      <td>11855</td>\n",
       "      <td>48944</td>\n",
       "      <td>85900</td>\n",
       "      <td>3409</td>\n",
       "      <td>1178</td>\n",
       "      <td>1926</td>\n",
       "      <td>52964</td>\n",
       "      <td>1804</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>30000</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36535</td>\n",
       "      <td>32428</td>\n",
       "      <td>15313</td>\n",
       "      <td>2078</td>\n",
       "      <td>1800</td>\n",
       "      <td>1430</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  \\\n",
       "0          1      20000    2          2         1   24      2      2     -1   \n",
       "1          2     120000    2          2         2   26     -1      2      0   \n",
       "2          3      90000    2          2         2   34      0      0      0   \n",
       "3          4      50000    2          2         1   37      0      0      0   \n",
       "4          5      50000    1          2         1   57     -1      0     -1   \n",
       "...      ...        ...  ...        ...       ...  ...    ...    ...    ...   \n",
       "29995  29996     220000    1          3         1   39      0      0      0   \n",
       "29996  29997     150000    1          3         2   43     -1     -1     -1   \n",
       "29997  29998      30000    1          2         2   37      4      3      2   \n",
       "29998  29999      80000    1          3         1   41      1     -1      0   \n",
       "29999  30000      50000    1          2         1   46      0      0      0   \n",
       "\n",
       "       PAY_4  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  \\\n",
       "0         -1  ...          0          0          0         0       689   \n",
       "1          0  ...       3272       3455       3261         0      1000   \n",
       "2          0  ...      14331      14948      15549      1518      1500   \n",
       "3          0  ...      28314      28959      29547      2000      2019   \n",
       "4          0  ...      20940      19146      19131      2000     36681   \n",
       "...      ...  ...        ...        ...        ...       ...       ...   \n",
       "29995      0  ...      88004      31237      15980      8500     20000   \n",
       "29996     -1  ...       8979       5190          0      1837      3526   \n",
       "29997     -1  ...      20878      20582      19357         0         0   \n",
       "29998      0  ...      52774      11855      48944     85900      3409   \n",
       "29999      0  ...      36535      32428      15313      2078      1800   \n",
       "\n",
       "       PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
       "0             0         0         0         0                           1  \n",
       "1          1000      1000         0      2000                           1  \n",
       "2          1000      1000      1000      5000                           0  \n",
       "3          1200      1100      1069      1000                           0  \n",
       "4         10000      9000       689       679                           0  \n",
       "...         ...       ...       ...       ...                         ...  \n",
       "29995      5003      3047      5000      1000                           0  \n",
       "29996      8998       129         0         0                           0  \n",
       "29997     22000      4200      2000      3100                           1  \n",
       "29998      1178      1926     52964      1804                           1  \n",
       "29999      1430      1000      1000      1000                           1  \n",
       "\n",
       "[30000 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('credit card.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6e56d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
